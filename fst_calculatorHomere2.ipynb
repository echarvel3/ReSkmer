{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the ref-dist-mat into numpy for array\n",
    "# 2. Replace array names with annotations\n",
    "# 3. Double for loop to calculate F1 and F2\n",
    "# 4. Use F measuremnts to calculated M and FST measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = np.genfromtxt(\"./data/Clupea_11jan24/11jan_jc_ref-dist-mat.txt.txt\", dtype=\"str\")\n",
    "annots = np.genfromtxt(\"./data/Clupea_11jan24/11jan_ClupeaAtmore_Fstannot.tsv\", dtype=\"str\")\n",
    "\n",
    "# dist_mat = numpy.genfromtxt(\"/home/echarvel/Desktop/calab_data/code_bases/Skmer-2/fst_test_data/test_matrix.txt\", dtype=\"str\")\n",
    "# annots = numpy.genfromtxt(\"/home/echarvel/Desktop/calab_data/code_bases/Skmer-2/fst_test_data/test_annots.txt\", dtype=\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in annots:\n",
    "    x = np.where(dist_mat == line[0])\n",
    "    for index in x: \n",
    "        try:\n",
    "            dist_mat[index[0]][index[1]] = line[1]\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unknown', 'GieczPoland9th13thcentury', 'MalaNieszawkaPoland14th-15thc', 'TrusoJanówPomorskiPoland80085', 'KolowbrzwegBudzistowoPoland75', 'SelsoVestbyDenmark10th11thcen', 'SelsoVestbyDenmark12901380CE', 'KarmoyNorway2002', 'MoreNorway2002', 'RisorNorway2003', 'MaseskarSweden2003', 'KalixFinland2002', 'KalmarsundSweden2010', 'IdefjordInnerNorway2010', 'IdefjordOuterNorway2010']\n"
     ]
    }
   ],
   "source": [
    "dist_dict = dict()\n",
    "\n",
    "for num1 in range(1, len(dist_mat[0])):\n",
    "    for num2 in range(1, len(dist_mat[0])):\n",
    "        if num1 != num2: \n",
    "            name1=dist_mat[0][num1]\n",
    "            name2=dist_mat[0][num2]\n",
    "            if name1 not in dist_dict:\n",
    "                dist_dict[name1] = dict()\n",
    "\n",
    "            if name2 not in dist_dict[name1]:\n",
    "                dist_dict[name1][name2] = [float(dist_mat[num1, num2])]\n",
    "            else: \n",
    "                dist_dict[name1][name2].append(float(dist_mat[num1, num2]))\n",
    "        if num1 == num2:\n",
    "            name1=name2=dist_mat[0][num1]\n",
    "            \n",
    "            if name1 not in dist_dict:\n",
    "                dist_dict[name1] = dict()\n",
    "\n",
    "            if name2 not in dist_dict[name1]:\n",
    "                dist_dict[name1][name2] = []\n",
    "\n",
    "key_list = list(dist_dict.keys())\n",
    "print(key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_empty_matrix(dist_dict, key_list):\n",
    "    matrix = [[0 for x in range(0, len(dist_dict)+1)] for x in range(0, len(dist_dict)+1)]\n",
    "    matrix[0][0]=\"sample\"\n",
    "    for x in range(0, len(dist_dict)):\n",
    "        matrix[0][x+1] = matrix[x+1][0] = (key_list[x])\n",
    "    return matrix\n",
    "\n",
    "def calculate_WC_FST(F1, F2, M):\n",
    "    numerator_wc_fst = F1 + F2\n",
    "    denominator_wc_fst = F1 + F2 + 2 * (1 / (M + 1)) * (M * (1 - F1) + (1 - F2))\n",
    "    WC_FST = numerator_wc_fst / denominator_wc_fst\n",
    "    return WC_FST\n",
    "\n",
    "def calculate_Nei_FST(F1, F2):\n",
    "    numerator_nei_fst = F1 + F2\n",
    "    denominator_nei_fst = 2 - ((F1 + F2) / 2)\n",
    "    Nei_FST = numerator_nei_fst / denominator_nei_fst\n",
    "    return Nei_FST\n",
    "\n",
    "def calculate_Hudson_FST(F1, F2):\n",
    "    Hudson_FST = (F1 + F2) / 2\n",
    "    return Hudson_FST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "F_mtrx = make_empty_matrix(dist_dict, key_list)\n",
    "wh_fst_mtrx = make_empty_matrix(dist_dict, key_list)\n",
    "wc_fst_mtrx = make_empty_matrix(dist_dict, key_list)\n",
    "nei_fst_mtrx = make_empty_matrix(dist_dict, key_list)\n",
    "hud_fst_mtrx = make_empty_matrix(dist_dict, key_list)\n",
    "clade_dist_mtrx = make_empty_matrix(dist_dict, key_list)\n",
    "thetas_list = [[key,0.0] for key in key_list]\n",
    "print(thetas_list[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unknown', 0.0]\n",
      "['GieczPoland9th13thcentury', 0.02172]\n",
      "['MalaNieszawkaPoland14th-15thc', 0.06176]\n",
      "['TrusoJanówPomorskiPoland80085', 0.07604]\n",
      "['KolowbrzwegBudzistowoPoland75', 'NA']\n",
      "['SelsoVestbyDenmark10th11thcen', 0.13479]\n",
      "['SelsoVestbyDenmark12901380CE', 0.06658]\n",
      "['KarmoyNorway2002', 0.00245]\n",
      "['MoreNorway2002', 'NA']\n",
      "['RisorNorway2003', 0.00624]\n",
      "['MaseskarSweden2003', 0.00283]\n",
      "['KalixFinland2002', 0.00622]\n",
      "['KalmarsundSweden2010', 0.00611]\n",
      "['IdefjordInnerNorway2010', 0.00381]\n",
      "['IdefjordOuterNorway2010', 0.01532]\n"
     ]
    }
   ],
   "source": [
    "for key1, index1 in zip(key_list, range(len(key_list))):\n",
    "     for key2, index2 in zip(key_list, range(len(key_list))):\n",
    "        if key1 == key2:\n",
    "            break\n",
    "        else:\n",
    "            dist_array_k1_k1 = dist_dict[key1][key1]\n",
    "            dist_array_k2_k2 = dist_dict[key2][key2]\n",
    "            dist_array_k1_k2 = dist_dict[key1][key2]\n",
    "\n",
    "            across_k1_k2 = sum(dist_array_k1_k2)/len(dist_array_k1_k2)\n",
    "\n",
    "            max_k1_k1 = max(dist_array_k1_k1) if (len(dist_array_k1_k1) != 0) else 0\n",
    "            max_k2_k2 = max(dist_array_k1_k1) if (len(dist_array_k1_k1) != 0) else 0\n",
    "            max_k1_k2 = max(dist_array_k1_k2) \n",
    "\n",
    "            clade_dist_mtrx[index1+1][index2+1] = clade_dist_mtrx[index2+1][index1+1] = max_k1_k2 - (max_k1_k1 + max_k2_k2)/2\n",
    " \n",
    "            if ((len(dist_array_k1_k1) == 0) or len(dist_array_k2_k2) == 0):\n",
    "                # Checks if any of the populations only have one members.\n",
    "                # Calculates F1 or F2 if possible. If not, assigns \"NA\". \n",
    "                # Assigns \"NA\" to all other Fst calculations.\n",
    "                if (len(dist_array_k1_k1) != 0):\n",
    "                    within_k1 = sum(dist_array_k1_k1)/len(dist_array_k1_k1)\n",
    "                    F1 = within_k1/across_k1_k2\n",
    "                    thetas_list[index1][1] = round(within_k1, 5)\n",
    "                    F_mtrx[index1+1][index2+1] = round(F1, 5)\n",
    "                    F_mtrx[index2+1][index1+1] = \"NA\"\n",
    "                elif (len(dist_array_k2_k2) != 0):\n",
    "                    within_k2 = sum(dist_array_k2_k2)/len(dist_array_k2_k2)\n",
    "                    F2 = within_k2/across_k1_k2\n",
    "                    thetas_list[index1][1] = \"NA\"\n",
    "                    F_mtrx[index1+1][index2+1] = \"NA\"\n",
    "                    F_mtrx[index2+1][index1+1] = round(F2, 5)\n",
    "                    \n",
    "                else:\n",
    "                    F_mtrx[index1+1][index2+1] = F_mtrx[index2+1][index1+1] =\"NA\"\n",
    "\n",
    "                wh_fst_mtrx[index1+1][index2+1] = wh_fst_mtrx[index2+1][index1+1] = \"NA\"\n",
    "                wc_fst_mtrx[index1+1][index2+1] = wc_fst_mtrx[index2+1][index1+1] = \"NA\"\n",
    "                nei_fst_mtrx[index1+1][index2+1] = nei_fst_mtrx[index2+1][index1+1] = \"NA\"\n",
    "                hud_fst_mtrx[index1+1][index2+1] = hud_fst_mtrx[index2+1][index1+1] = \"NA\"\n",
    "            else:\n",
    "                within_k1 = sum(dist_array_k1_k1)/len(dist_array_k1_k1)\n",
    "                within_k2 = sum(dist_array_k2_k2)/len(dist_array_k2_k2)\n",
    "\n",
    "                F1 = within_k1/across_k1_k2\n",
    "                F2 = within_k2/across_k1_k2\n",
    "\n",
    "                if len(dist_array_k1_k1) <= len(dist_array_k2_k2):\n",
    "                    M=len(dist_array_k1_k1)/len(dist_array_k2_k2)\n",
    "                else:\n",
    "                    M=len(dist_array_k2_k2)/len(dist_array_k1_k1)\n",
    "                \n",
    "                thetas_list[index1][1] = round(within_k1, 5)\n",
    "                # NOTE: F_matrix contains F1 in the lower half and F2 in the upper half. \n",
    "                F_mtrx[index1+1][index2+1] =  round(F1, 5)\n",
    "                F_mtrx[index2+1][index1+1] =  round(F2, 5)\n",
    "                wh_fst_mtrx[index1+1][index2+1] = wh_fst_mtrx[index2+1][index1+1] = round((F1 + F2)/2, 5)\n",
    "                wc_fst_mtrx[index1+1][index2+1] = wc_fst_mtrx[index2+1][index1+1] = round(calculate_WC_FST(F1, F2, M), 5)\n",
    "                nei_fst_mtrx[index1+1][index2+1] = nei_fst_mtrx[index2+1][index1+1] = round(calculate_Nei_FST(F1, F2), 5)\n",
    "                hud_fst_mtrx[index1+1][index2+1] = hud_fst_mtrx[index2+1][index1+1] =  round(calculate_Hudson_FST(F1, F2), 5)\n",
    "for x in thetas_list:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"./ed_test_thetas.txt\", np.matrix(thetas_list), fmt=\"%s\", delimiter=\"\\t\")\n",
    "np.savetxt(\"./ed_test_Fmat.txt\", np.matrix(F_mtrx), fmt=\"%s\", delimiter=\"\\t\")\n",
    "np.savetxt(\"./ed_test_whfst.txt\", np.matrix(wh_fst_mtrx), fmt=\"%s\", delimiter=\"\\t\")\n",
    "np.savetxt(\"./ed_test_wcfst.txt\", np.matrix(wc_fst_mtrx), fmt=\"%s\", delimiter=\"\\t\")\n",
    "np.savetxt(\"./ed_test_neifst.txt\", np.matrix(nei_fst_mtrx), fmt=\"%s\", delimiter=\"\\t\")\n",
    "np.savetxt(\"./ed_test_hudfst.txt\", np.matrix(hud_fst_mtrx), fmt=\"%s\", delimiter=\"\\t\")\n",
    "np.savetxt(\"./ed_test_cladedist.txt\", np.matrix(clade_dist_mtrx), fmt=\"%s\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
